{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Space Invaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import gym\n",
    "from gym import error, spaces\n",
    "from gym import utils\n",
    "from gym.utils import seeding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ram(ale):\n",
    "    ram_size = ale.getRAMSize()\n",
    "    ram = np.zeros((ram_size),dtype=np.uint8)\n",
    "    ale.getRAM(ram)\n",
    "    return ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariEnv(gym.Env, utils.EzPickle):\n",
    "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "\n",
    "    def __init__(self, game='space_invaders', obs_type='ram', frameskip=(2, 5), repeat_action_probability=0.):\n",
    "        \"\"\"Frameskip should be either a tuple (indicating a random range to\n",
    "        choose from, with the top value exclude), or an int.\"\"\"\n",
    "\n",
    "        utils.EzPickle.__init__(self, game, obs_type, frameskip, repeat_action_probability)\n",
    "        assert obs_type in ('ram', 'image')\n",
    "\n",
    "        self.game_path = atari_py.get_game_path(game)\n",
    "        if not os.path.exists(self.game_path):\n",
    "            raise IOError('You asked for game %s but path %s does not exist'%(game, self.game_path))\n",
    "        self._obs_type = obs_type\n",
    "        self.frameskip = frameskip\n",
    "        self.ale = atari_py.ALEInterface()\n",
    "        self.viewer = None\n",
    "\n",
    "        # Tune (or disable) ALE's action repeat:\n",
    "        # https://github.com/openai/gym/issues/349\n",
    "        assert isinstance(repeat_action_probability, (float, int)), \"Invalid repeat_action_probability: {!r}\".format(repeat_action_probability)\n",
    "        self.ale.setFloat('repeat_action_probability'.encode('utf-8'), repeat_action_probability)\n",
    "\n",
    "        self.seed()\n",
    "\n",
    "        self._action_set = self.ale.getMinimalActionSet()\n",
    "        self.action_space = spaces.Discrete(len(self._action_set))\n",
    "\n",
    "        (screen_width,screen_height) = self.ale.getScreenDims()\n",
    "        if self._obs_type == 'ram':\n",
    "            self.observation_space = spaces.Box(low=0, high=255, dtype=np.uint8, shape=(128,))\n",
    "        elif self._obs_type == 'image':\n",
    "            self.observation_space = spaces.Box(low=0, high=255, shape=(screen_height, screen_width, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            raise error.Error('Unrecognized observation type: {}'.format(self._obs_type))\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed1 = seeding.np_random(seed)\n",
    "        # Derive a random seed. This gets passed as a uint, but gets\n",
    "        # checked as an int elsewhere, so we need to keep it below\n",
    "        # 2**31.\n",
    "        seed2 = seeding.hash_seed(seed1 + 1) % 2**31\n",
    "        # Empirically, we need to seed before loading the ROM.\n",
    "        self.ale.setInt(b'random_seed', seed2)\n",
    "        self.ale.loadROM(self.game_path)\n",
    "        return [seed1, seed2]\n",
    "\n",
    "    def step(self, a):\n",
    "        reward = 0.0\n",
    "        action = self._action_set[a]\n",
    "\n",
    "        if isinstance(self.frameskip, int):\n",
    "            num_steps = self.frameskip\n",
    "        else:\n",
    "            num_steps = self.np_random.randint(self.frameskip[0], self.frameskip[1])\n",
    "        for _ in range(num_steps):\n",
    "            reward += self.ale.act(action)\n",
    "        ob = self._get_obs()\n",
    "\n",
    "        return ob, reward, self.ale.game_over(), {\"ale.lives\": self.ale.lives()}\n",
    "\n",
    "    def _get_image(self):\n",
    "        return self.ale.getScreenRGB2()\n",
    "\n",
    "    def _get_ram(self):\n",
    "        return to_ram(self.ale)\n",
    "\n",
    "    @property\n",
    "    def _n_actions(self):\n",
    "        return len(self._action_set)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        if self._obs_type == 'ram':\n",
    "            return self._get_ram()\n",
    "        elif self._obs_type == 'image':\n",
    "            img = self._get_image()\n",
    "        return img\n",
    "\n",
    "    # return: (states, observations)\n",
    "    def reset(self):\n",
    "        self.ale.reset_game()\n",
    "        return self._get_obs()\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        img = self._get_image()\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "    def get_action_meanings(self):\n",
    "        return [ACTION_MEANING[i] for i in self._action_set]\n",
    "\n",
    "    def get_keys_to_action(self):\n",
    "        KEYWORD_TO_KEY = {\n",
    "            'UP':      ord('w'),\n",
    "            'DOWN':    ord('s'),\n",
    "            'LEFT':    ord('a'),\n",
    "            'RIGHT':   ord('d'),\n",
    "            'FIRE':    ord(' '),\n",
    "        }\n",
    "\n",
    "        keys_to_action = {}\n",
    "\n",
    "        for action_id, action_meaning in enumerate(self.get_action_meanings()):\n",
    "            keys = []\n",
    "            for keyword, key in KEYWORD_TO_KEY.items():\n",
    "                if keyword in action_meaning:\n",
    "                    keys.append(key)\n",
    "            keys = tuple(sorted(keys))\n",
    "\n",
    "            assert keys not in keys_to_action\n",
    "            keys_to_action[keys] = action_id\n",
    "\n",
    "        return keys_to_action\n",
    "\n",
    "    def clone_state(self):\n",
    "        \"\"\"Clone emulator state w/o system state. Restoring this state will\n",
    "        *not* give an identical environment. For complete cloning and restoring\n",
    "        of the full state, see `{clone,restore}_full_state()`.\"\"\"\n",
    "        state_ref = self.ale.cloneState()\n",
    "        state = self.ale.encodeState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "        return state\n",
    "\n",
    "    def restore_state(self, state):\n",
    "        \"\"\"Restore emulator state w/o system state.\"\"\"\n",
    "        state_ref = self.ale.decodeState(state)\n",
    "        self.ale.restoreState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "\n",
    "    def clone_full_state(self):\n",
    "        \"\"\"Clone emulator state w/ system state including pseudorandomness.\n",
    "        Restoring this state will give an identical environment.\"\"\"\n",
    "        state_ref = self.ale.cloneSystemState()\n",
    "        state = self.ale.encodeState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "        return state\n",
    "\n",
    "    def restore_full_state(self, state):\n",
    "        \"\"\"Restore emulator state w/ system state including pseudorandomness.\"\"\"\n",
    "        state_ref = self.ale.decodeState(state)\n",
    "        self.ale.restoreSystemState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "\n",
    "ACTION_MEANING = {\n",
    "    0 : \"NOOP\",\n",
    "    1 : \"FIRE\",\n",
    "    2 : \"UP\",\n",
    "    3 : \"RIGHT\",\n",
    "    4 : \"LEFT\",\n",
    "    5 : \"DOWN\",\n",
    "    6 : \"UPRIGHT\",\n",
    "    7 : \"UPLEFT\",\n",
    "    8 : \"DOWNRIGHT\",\n",
    "    9 : \"DOWNLEFT\",\n",
    "    10 : \"UPFIRE\",\n",
    "    11 : \"RIGHTFIRE\",\n",
    "    12 : \"LEFTFIRE\",\n",
    "    13 : \"DOWNFIRE\",\n",
    "    14 : \"UPRIGHTFIRE\",\n",
    "    15 : \"UPLEFTFIRE\",\n",
    "    16 : \"DOWNRIGHTFIRE\",\n",
    "    17 : \"DOWNLEFTFIRE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render('human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()  # https://github.com/openai/gym/issues/893"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
