{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Space Invaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ee80affde6fb>:87: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Total R: 65.0\n",
      "Total R: 120.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Elapsed time(s):  0\n",
      "Total R: 125.0\n",
      "Total R: 155.0\n",
      "Total R: 260.0\n",
      "Total R: 45.0\n",
      "Total R: 10.0\n",
      "Total R: 85.0\n",
      "Total R: 75.0\n",
      "Total R: 350.0\n",
      "Elapsed time(s):  10\n",
      "Total R: 95.0\n",
      "Total R: 90.0\n",
      "Total R: 135.0\n",
      "Total R: 205.0\n",
      "Total R: 105.0\n",
      "Total R: 85.0\n",
      "Total R: 150.0\n",
      "Elapsed time(s):  20\n",
      "Total R: 45.0\n",
      "Total R: 80.0\n",
      "Total R: 15.0\n",
      "Total R: 425.0\n",
      "Total R: 65.0\n",
      "Total R: 35.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  30\n",
      "Total R: 110.0\n",
      "Total R: 105.0\n",
      "Total R: 230.0\n",
      "Total R: 290.0\n",
      "Total R: 215.0\n",
      "Total R: 120.0\n",
      "Total R: 80.0\n",
      "Elapsed time(s):  40\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 135.0\n",
      "Total R: 135.0\n",
      "Total R: 140.0\n",
      "Total R: 190.0\n",
      "Elapsed time(s):  50\n",
      "Total R: 165.0\n",
      "Total R: 180.0\n",
      "Total R: 105.0\n",
      "Total R: 55.0\n",
      "Total R: 120.0\n",
      "Total R: 110.0\n",
      "Total R: 75.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  60\n",
      "Total R: 120.0\n",
      "Total R: 160.0\n",
      "Total R: 190.0\n",
      "Total R: 370.0\n",
      "Total R: 35.0\n",
      "Total R: 410.0\n",
      "Elapsed time(s):  70\n",
      "Total R: 305.0\n",
      "Total R: 45.0\n",
      "Total R: 80.0\n",
      "Total R: 190.0\n",
      "Total R: 305.0\n",
      "Total R: 125.0\n",
      "Total R: 920.0\n",
      "Elapsed time(s):  80\n",
      "Total R: 130.0\n",
      "Total R: 50.0\n",
      "Total R: 120.0\n",
      "Total R: 75.0\n",
      "Total R: 95.0\n",
      "Total R: 60.0\n",
      "Elapsed time(s):  90\n",
      "Total R: 200.0\n",
      "Total R: 45.0\n",
      "Total R: 260.0\n",
      "Total R: 205.0\n",
      "Total R: 105.0\n",
      "Total R: 60.0\n",
      "Elapsed time(s):  100\n",
      "Total R: 80.0\n",
      "Total R: 180.0\n",
      "Total R: 155.0\n",
      "Total R: 75.0\n",
      "Total R: 175.0\n",
      "Total R: 665.0\n",
      "Elapsed time(s):  110\n",
      "Total R: 320.0\n",
      "Total R: 295.0\n",
      "Total R: 155.0\n",
      "Total R: 100.0\n",
      "Total R: 135.0\n",
      "Total R: 280.0\n",
      "Total R: 30.0\n",
      "Total R: 20.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  120\n",
      "Total R: 195.0\n",
      "Total R: 170.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  130\n",
      "Total R: 315.0\n",
      "Total R: 120.0\n",
      "Total R: 245.0\n",
      "Total R: 185.0\n",
      "Total R: 320.0\n",
      "Total R: 135.0\n",
      "Total R: 310.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  140\n",
      "Total R: 5.0\n",
      "Total R: 105.0\n",
      "Total R: 315.0\n",
      "Total R: 105.0\n",
      "Total R: 125.0\n",
      "Total R: 165.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  150\n",
      "Total R: 105.0\n",
      "Total R: 120.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 5.0\n",
      "Total R: 150.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  160\n",
      "Total R: 110.0\n",
      "Total R: 50.0\n",
      "Total R: 20.0\n",
      "Total R: 65.0\n",
      "Total R: 50.0\n",
      "Total R: 80.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  170\n",
      "Total R: 440.0\n",
      "Total R: 105.0\n",
      "Total R: 95.0\n",
      "Total R: 110.0\n",
      "Total R: 220.0\n",
      "Total R: 120.0\n",
      "Total R: 280.0\n",
      "Elapsed time(s):  180\n",
      "Total R: 150.0\n",
      "Total R: 120.0\n",
      "Total R: 120.0\n",
      "Total R: 120.0\n",
      "Total R: 105.0\n",
      "Total R: 130.0\n",
      "Total R: 145.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  190\n",
      "Total R: 125.0\n",
      "Total R: 110.0\n",
      "Total R: 120.0\n",
      "Total R: 265.0\n",
      "Total R: 205.0\n",
      "Elapsed time(s):  200\n",
      "Total R: 65.0\n",
      "Total R: 410.0\n",
      "Total R: 180.0\n",
      "Total R: 145.0\n",
      "Total R: 270.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 90.0\n",
      "Total R: 55.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  210\n",
      "Total R: 80.0\n",
      "Total R: 190.0\n",
      "Total R: 110.0\n",
      "Total R: 125.0\n",
      "Total R: 180.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  220\n",
      "Total R: 135.0\n",
      "Total R: 120.0\n",
      "Total R: 185.0\n",
      "Total R: 150.0\n",
      "Total R: 45.0\n",
      "Total R: 155.0\n",
      "Total R: 485.0\n",
      "Elapsed time(s):  230\n",
      "Total R: 35.0\n",
      "Total R: 155.0\n",
      "Total R: 355.0\n",
      "Total R: 105.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  240\n",
      "Total R: 110.0\n",
      "Total R: 155.0\n",
      "Total R: 300.0\n",
      "Total R: 120.0\n",
      "Total R: 240.0\n",
      "Total R: 120.0\n",
      "Total R: 120.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  250\n",
      "Total R: 80.0\n",
      "Total R: 60.0\n",
      "Total R: 75.0\n",
      "Total R: 45.0\n",
      "Total R: 75.0\n",
      "Total R: 120.0\n",
      "Total R: 170.0\n",
      "Elapsed time(s):  260\n",
      "Total R: 120.0\n",
      "Total R: 30.0\n",
      "Total R: 155.0\n",
      "Total R: 240.0\n",
      "Total R: 55.0\n",
      "Total R: 320.0\n",
      "Elapsed time(s):  270\n",
      "Total R: 105.0\n",
      "Total R: 185.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Total R: 120.0\n",
      "Total R: 205.0\n",
      "Total R: 65.0\n",
      "Total R: 80.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  280\n",
      "Total R: 170.0\n",
      "Total R: 390.0\n",
      "Total R: 105.0\n",
      "Total R: 170.0\n",
      "Total R: 180.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  290\n",
      "Total R: 110.0\n",
      "Total R: 50.0\n",
      "Total R: 125.0\n",
      "Total R: 180.0\n",
      "Total R: 80.0\n",
      "Total R: 170.0\n",
      "Elapsed time(s):  300\n",
      "Total R: 210.0\n",
      "Total R: 80.0\n",
      "Total R: 320.0\n",
      "Total R: 140.0\n",
      "Total R: 355.0\n",
      "Total R: 60.0\n",
      "Total R: 165.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  310\n",
      "Total R: 45.0\n",
      "Total R: 185.0\n",
      "Total R: 210.0\n",
      "Total R: 60.0\n",
      "Total R: 190.0\n",
      "Total R: 205.0\n",
      "Elapsed time(s):  320\n",
      "Total R: 105.0\n",
      "Total R: 100.0\n",
      "Total R: 155.0\n",
      "Total R: 410.0\n",
      "Total R: 120.0\n",
      "Total R: 75.0\n",
      "Total R: 485.0\n",
      "Elapsed time(s):  330\n",
      "Total R: 120.0\n",
      "Total R: 380.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  340\n",
      "Total R: 180.0\n",
      "Total R: 515.0\n",
      "Total R: 240.0\n",
      "Total R: 210.0\n",
      "Total R: 90.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  350\n",
      "Total R: 565.0\n",
      "Total R: 475.0\n",
      "Total R: 155.0\n",
      "Total R: 60.0\n",
      "Total R: 565.0\n",
      "Elapsed time(s):  360\n",
      "Total R: 165.0\n",
      "Total R: 105.0\n",
      "Total R: 30.0\n",
      "Total R: 140.0\n",
      "Total R: 355.0\n",
      "Total R: 380.0\n",
      "Total R: 105.0\n",
      "Total R: 270.0\n",
      "Elapsed time(s):  370\n",
      "Total R: 50.0\n",
      "Total R: 260.0\n",
      "Total R: 380.0\n",
      "Total R: 55.0\n",
      "Total R: 215.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  380\n",
      "Total R: 60.0\n",
      "Total R: 215.0\n",
      "Total R: 210.0\n",
      "Total R: 5.0\n",
      "Total R: 125.0\n",
      "Elapsed time(s):  390\n",
      "Total R: 135.0\n",
      "Total R: 155.0\n",
      "Total R: 215.0\n",
      "Total R: 105.0\n",
      "Total R: 210.0\n",
      "Total R: 30.0\n",
      "Total R: 85.0\n",
      "Total R: 125.0\n",
      "Total R: 140.0\n",
      "Elapsed time(s):  400\n",
      "Total R: 260.0\n",
      "Total R: 135.0\n",
      "Total R: 195.0\n",
      "Total R: 55.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  410\n",
      "Total R: 210.0\n",
      "Total R: 75.0\n",
      "Total R: 120.0\n",
      "Total R: 145.0\n",
      "Total R: 105.0\n",
      "Total R: 110.0\n",
      "Total R: 80.0\n",
      "Total R: 135.0\n",
      "Total R: 210.0\n",
      "Total R: 85.0\n",
      "Elapsed time(s):  420\n",
      "Total R: 215.0\n",
      "Total R: 155.0\n",
      "Total R: 65.0\n",
      "Elapsed time(s):  430\n",
      "Total R: 210.0\n",
      "Total R: 180.0\n",
      "Total R: 185.0\n",
      "Total R: 125.0\n",
      "Total R: 150.0\n",
      "Total R: 25.0\n",
      "Total R: 50.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  440\n",
      "Total R:Total R: 75.0 125.0\n",
      "Total R: 140.0\n",
      "\n",
      "Total R: 145.0\n",
      "Total R: 60.0\n",
      "Total R: 50.0\n",
      "Total R: 210.0\n",
      "Total R: 110.0\n",
      "Total R: 5.0\n",
      "Elapsed time(s):  450\n",
      "Total R: 135.0\n",
      "Total R: 225.0\n",
      "Total R: 425.0\n",
      "Total R: 135.0\n",
      "Total R: 245.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  460\n",
      "Total R: 50.0\n",
      "Total R: 215.0\n",
      "Total R: 390.0\n",
      "Total R: 110.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  470\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Total R: 180.0\n",
      "Total R: 50.0\n",
      "Total R: 370.0\n",
      "Total R: 135.0\n",
      "Total R: 225.0\n",
      "Elapsed time(s):  480\n",
      "Total R: 185.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Total R: 240.0\n",
      "Total R: 180.0\n",
      "Total R: 60.0\n",
      "Total R: 455.0\n",
      "Elapsed time(s):  490\n",
      "Total R: 50.0\n",
      "Total R: 75.0\n",
      "Total R: 30.0\n",
      "Total R: 45.0\n",
      "Total R: 615.0\n",
      "Elapsed time(s):  500\n",
      "Total R: 180.0\n",
      "Total R: 140.0\n",
      "Total R: 55.0\n",
      "Total R: 250.0\n",
      "Total R: 260.0\n",
      "Total R: 50.0\n",
      "Total R: 75.0\n",
      "Total R: 135.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  510\n",
      "Total R: 190.0\n",
      "Total R: 105.0\n",
      "Total R: 155.0\n",
      "Total R: 125.0\n",
      "Total R: 180.0\n",
      "Total R: 165.0\n",
      "Total R: 90.0\n",
      "Elapsed time(s):  520\n",
      "Total R: 210.0\n",
      "Total R: 120.0\n",
      "Total R: 125.0\n",
      "Total R: 55.0\n",
      "Total R: 20.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  530\n",
      "Total R: 180.0\n",
      "Total R: 240.0\n",
      "Total R: 50.0\n",
      "Total R: 120.0\n",
      "Total R: 115.0\n",
      "Total R: 105.0\n",
      "Total R: 55.0\n",
      "Total R: 45.0\n",
      "Elapsed time(s):  540\n",
      "Total R: 115.0\n",
      "Total R: 45.0\n",
      "Total R: 145.0\n",
      "Total R: 135.0\n",
      "Total R: 65.0\n",
      "Total R: 80.0\n",
      "Total R: 60.0\n",
      "Total R: 30.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  550\n",
      "Total R: 120.0\n",
      "Total R: 15.0\n",
      "Total R: 45.0\n",
      "Total R: 260.0\n",
      "Total R: 210.0\n",
      "Total R: 55.0\n",
      "Total R: 410.0\n",
      "Elapsed time(s):  560\n",
      "Total R: 265.0\n",
      "Total R: 105.0\n",
      "Total R: 35.0\n",
      "Total R: 135.0\n",
      "Total R: 45.0\n",
      "Total R: 55.0\n",
      "Total R: 175.0\n",
      "Total R: 80.0\n",
      "Elapsed time(s):  570\n",
      "Total R: 350.0\n",
      "Total R: 125.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  580\n",
      "Total R: 120.0\n",
      "Total R: 210.0\n",
      "Total R: 185.0\n",
      "Total R: 195.0\n",
      "Total R: 135.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  590\n",
      "Total R: 105.0\n",
      "Total R: 135.0\n",
      "Total R: 110.0\n",
      "Total R: 210.0\n",
      "Total R: 260.0\n",
      "Total R: 380.0\n",
      "Elapsed time(s):  600\n",
      "Total R: 160.0\n",
      "Total R: 150.0\n",
      "Total R: 450.0\n",
      "Total R: 110.0\n",
      "Total R: 120.0\n",
      "Total R: 110.0\n",
      "Total R: 155.0\n",
      "Total R: 75.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  610\n",
      "Total R: 105.0\n",
      "Total R: 80.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  620\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Total R: 60.0\n",
      "Total R: 135.0\n",
      "Total R: 105.0\n",
      "Total R: 285.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  630\n",
      "Total R: 120.0\n",
      "Total R: 55.0\n",
      "Total R: 65.0\n",
      "Total R: 110.0\n",
      "Total R: 235.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  640\n",
      "Total R: 120.0\n",
      "Total R: 30.0\n",
      "Total R:Total R: 120.0\n",
      " 20.0\n",
      "Total R: 135.0\n",
      "Total R: 460.0\n",
      "Elapsed time(s):  650\n",
      "Total R: 105.0\n",
      "Total R: 55.0\n",
      "Total R: 110.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total R: 155.0\n",
      "Total R: 240.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  660\n",
      "Total R: 120.0\n",
      "Total R: 405.0\n",
      "Total R: 425.0\n",
      "Total R: 210.0\n",
      "Total R: 100.0\n",
      "Total R: 210.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  670\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 90.0\n",
      "Total R: 320.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  680\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Total R: 155.0\n",
      "Total R: 105.0\n",
      "Total R: 115.0\n",
      "Total R: 180.0\n",
      "Total R: 155.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  690\n",
      "Total R: 210.0\n",
      "Total R: 110.0\n",
      "Total R: 75.0\n",
      "Total R: 110.0\n",
      "Total R: 30.0\n",
      "Total R: 35.0\n",
      "Total R: 55.0\n",
      "Elapsed time(s):  700\n",
      "Total R: 160.0\n",
      "Total R: 180.0\n",
      "Total R: 165.0\n",
      "Total R: 135.0\n",
      "Total R: 30.0\n",
      "Total R: 75.0\n",
      "Total R: 155.0\n",
      "Elapsed time(s):  710\n",
      "Total R: 120.0\n",
      "Total R: 210.0\n",
      "Total R: 155.0\n",
      "Total R: 110.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  720\n",
      "Total R: 65.0\n",
      "Total R: 75.0\n",
      "Total R: 120.0\n",
      "Total R: 155.0\n",
      "Total R: 180.0\n",
      "Total R: 15.0\n",
      "Total R: 120.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  730\n",
      "Total R: 110.0\n",
      "Total R: 75.0\n",
      "Total R: 155.0\n",
      "Total R: 30.0\n",
      "Total R: 210.0\n",
      "Total R: 255.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  740\n",
      "Total R: 110.0\n",
      "Total R: 205.0\n",
      "Total R: 30.0\n",
      "Total R: 105.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  750\n",
      "Total R: 135.0\n",
      "Total R: 340.0\n",
      "Total R: 50.0\n",
      "Total R: 90.0\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  760\n",
      "Total R: 170.0\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Total R: 60.0\n",
      "Total R: 30.0\n",
      "Total R: 120.0\n",
      "Total R: 355.0\n",
      "Elapsed time(s):  770\n",
      "Total R: 75.0\n",
      "Total R: 90.0\n",
      "Total R: 65.0\n",
      "Total R: 90.0\n",
      "Total R: 190.0\n",
      "Total R: 80.0\n",
      "Total R: 355.0\n",
      "Total R: 55.0\n",
      "Elapsed time(s):  780\n",
      "Total R: 80.0\n",
      "Total R: 320.0\n",
      "Total R: 135.0\n",
      "Total R: 115.0\n",
      "Total R: 135.0\n",
      "Total R: 205.0\n",
      "Elapsed time(s):  790\n",
      "Total R: 210.0\n",
      "Total R: 260.0\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Total R: 80.0\n",
      "Total R: 55.0\n",
      "Elapsed time(s):  800\n",
      "Total R: 295.0\n",
      "Total R: 70.0\n",
      "Total R: 80.0\n",
      "Total R: 240.0\n",
      "Total R: 345.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  810\n",
      "Total R: 30.0\n",
      "Total R: 55.0\n",
      "Total R: 210.0\n",
      "Total R: 75.0\n",
      "Total R: 225.0\n",
      "Elapsed time(s):  820\n",
      "Total R: 270.0\n",
      "Total R: 125.0\n",
      "Total R: 110.0\n",
      "Total R: 150.0\n",
      "Total R: 105.0\n",
      "Total R: 80.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  830\n",
      "Total R: 105.0\n",
      "Total R: 170.0\n",
      "Total R: 155.0\n",
      "Total R: 60.0\n",
      "Elapsed time(s):  840\n",
      "Total R: 145.0\n",
      "Total R: 180.0\n",
      "Total R: 355.0\n",
      "Total R: 195.0\n",
      "Total R: 105.0\n",
      "Total R: 210.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  850\n",
      "Total R: 85.0\n",
      "Total R: 110.0\n",
      "Total R: 210.0\n",
      "Total R: 160.0\n",
      "Total R: 60.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  860\n",
      "Total R: 100.0\n",
      "Total R: 65.0\n",
      "Total R: 30.0\n",
      "Total R: 345.0\n",
      "Total R: 185.0\n",
      "Total R: 55.0\n",
      "Total R: 65.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  870\n",
      "Total R: 30.0\n",
      "Total R: 35.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 100.0\n",
      "Total R: 190.0\n",
      "Total R: 150.0\n",
      "Elapsed time(s):  880\n",
      "Total R: 290.0\n",
      "Total R: 110.0\n",
      "Total R: 120.0\n",
      "Total R: 135.0\n",
      "Total R: 210.0\n",
      "Total R: 50.0\n",
      "Total R: 55.0\n",
      "Elapsed time(s):  890\n",
      "Total R: 170.0\n",
      "Total R: 180.0\n",
      "Total R: 210.0\n",
      "Total R: 120.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  900\n",
      "Total R: 165.0\n",
      "Total R: 210.0\n",
      "Total R: 240.0\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 80.0\n",
      "Total R: 120.0\n",
      "Total R: 5.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  910\n",
      "Total R: 155.0\n",
      "Total R: 255.0\n",
      "Total R: 155.0\n",
      "Total R: 225.0\n",
      "Total R: 155.0\n",
      "Elapsed time(s):  920\n",
      "Total R: 120.0\n",
      "Total R: 210.0\n",
      "Total R: 15.0\n",
      "Total R: 105.0\n",
      "Total R: 55.0\n",
      "Elapsed time(s):  930\n",
      "Total R: 210.0\n",
      "Total R: 0.0\n",
      "Total R: 120.0\n",
      "Total R: 225.0\n",
      "Total R: 385.0\n",
      "Total R: 95.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  940\n",
      "Total R: 195.0\n",
      "Total R: 110.0\n",
      "Total R: 110.0\n",
      "Total R: 305.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  950\n",
      "Total R: 220.0\n",
      "Total R: 160.0\n",
      "Total R: 225.0\n",
      "Total R: 30.0\n",
      "Total R: 180.0\n",
      "Total R: 50.0\n",
      "Total R: 180.0\n",
      "Total R: 345.0\n",
      "Elapsed time(s):  960\n",
      "Total R: 15.0\n",
      "Total R: 105.0\n",
      "Total R: 180.0\n",
      "Total R: 45.0\n",
      "Elapsed time(s):  970\n",
      "Total R: 195.0\n",
      "Total R: 185.0\n",
      "Total R: 180.0\n",
      "Total R: 425.0\n",
      "Total R: 110.0\n",
      "Total R: 155.0\n",
      "Elapsed time(s):  980\n",
      "Total R: 65.0\n",
      "Total R: 240.0\n",
      "Total R: 105.0\n",
      "Total R: 65.0\n",
      "Total R: 135.0\n",
      "Total R: 35.0\n",
      "Total R: 210.0\n",
      "Total R: 160.0\n",
      "Elapsed time(s):  990\n",
      "Total R: 100.0\n",
      "Total R: 120.0\n",
      "Total R: 180.0\n",
      "Total R: 75.0\n",
      "Total R: 110.0\n",
      "Total R: 30.0\n",
      "Total R: 185.0\n",
      "Elapsed time(s):  1000\n",
      "Total R: 30.0\n",
      "Total R: 135.0\n",
      "Total R: 180.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 75.0\n",
      "Total R: 485.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  1010\n",
      "Total R: 35.0\n",
      "Total R: 80.0\n",
      "Total R: 125.0\n",
      "Total R: 50.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1020\n",
      "Total R: 105.0\n",
      "Total R: 55.0\n",
      "Total R: 285.0\n",
      "Total R: 210.0\n",
      "Total R:Total R:  30.0\n",
      "135.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1030\n",
      "Total R: 120.0\n",
      "Total R: 440.0\n",
      "Total R: 55.0\n",
      "Total R: 180.0\n",
      "Total R: 120.0\n",
      "Total R: 105.0\n",
      "Total R: 255.0\n",
      "Total R: 180.0\n",
      "Elapsed time(s):  1040\n",
      "Total R: 110.0\n",
      "Total R: 90.0\n",
      "Total R: 30.0\n",
      "Total R: 75.0\n",
      "Total R: 75.0\n",
      "Total R: 35.0\n",
      "Total R: 150.0\n",
      "Elapsed time(s):  1050\n",
      "Total R: 5.0\n",
      "Total R: 45.0\n",
      "Total R: 155.0\n",
      "Total R: 105.0\n",
      "Total R: 40.0\n",
      "Total R: 305.0\n",
      "Elapsed time(s):  1060\n",
      "Total R: 125.0\n",
      "Total R: 180.0\n",
      "Total R: 145.0\n",
      "Total R: 160.0\n",
      "Total R: 155.0\n",
      "Total R: 75.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1070\n",
      "Total R: 465.0\n",
      "Total R: 110.0\n",
      "Total R: 105.0\n",
      "Total R: 65.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1080\n",
      "Total R: 260.0\n",
      "Total R: 150.0\n",
      "Total R: 105.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1090\n",
      "Total R: 30.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 205.0\n",
      "Total R: 260.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1100\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Total R: 215.0\n",
      "Total R: 55.0\n",
      "Total R: 60.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  1110\n",
      "Total R: 165.0\n",
      "Total R: 180.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 240.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1120\n",
      "Total R: 30.0\n",
      "Total R: 50.0\n",
      "Total R: 210.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Total R: 65.0\n",
      "Total R: 120.0\n",
      "Total R: 50.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1130\n",
      "Total R: 75.0\n",
      "Total R: 135.0\n",
      "Total R: 50.0\n",
      "Total R: 230.0\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  1140\n",
      "Total R: 335.0\n",
      "Total R: 50.0\n",
      "Total R: 50.0\n",
      "Total R: 50.0\n",
      "Total R: 185.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1150\n",
      "Total R: 90.0\n",
      "Total R: 75.0\n",
      "Total R: 50.0\n",
      "Total R: 155.0\n",
      "Total R: 120.0\n",
      "Total R: 355.0\n",
      "Elapsed time(s):  1160\n",
      "Total R: 105.0\n",
      "Total R: 335.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Total R: 310.0\n",
      "Elapsed time(s):  1170\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 425.0\n",
      "Total R: 45.0\n",
      "Total R: 285.0\n",
      "Total R: 155.0\n",
      "Total R: 230.0\n",
      "Elapsed time(s):  1180\n",
      "Total R: 135.0\n",
      "Total R: 180.0\n",
      "Total R: 155.0\n",
      "Total R: 120.0\n",
      "Total R: 150.0\n",
      "Total R: 155.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1190\n",
      "Total R: 105.0\n",
      "Total R: 135.0\n",
      "Total R: 45.0\n",
      "Total R: 40.0\n",
      "Total R: 45.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  1200\n",
      "Total R: 215.0\n",
      "Total R: 65.0\n",
      "Total R: 25.0\n",
      "Total R: 290.0\n",
      "Total R: 110.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1210\n",
      "Total R: 50.0\n",
      "Total R: 305.0\n",
      "Total R: 135.0\n",
      "Total R: 25.0\n",
      "Total R: 5.0\n",
      "Total R: 110.0\n",
      "Total R: 105.0\n",
      "Total R: 15.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1220\n",
      "Total R: 30.0\n",
      "Total R: 110.0\n",
      "Total R: 50.0\n",
      "Total R: 110.0\n",
      "Total R: 180.0\n",
      "Total R: 185.0\n",
      "Elapsed time(s):  1230\n",
      "Total R: 355.0\n",
      "Total R: 225.0\n",
      "Total R: 80.0\n",
      "Total R: 135.0\n",
      "Total R: 210.0\n",
      "Elapsed time(s):  1240\n",
      "Total R: 135.0\n",
      "Total R: 245.0\n",
      "Total R: 360.0\n",
      "Total R: 180.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1250\n",
      "Total R: 165.0\n",
      "Total R: 130.0\n",
      "Total R: 120.0\n",
      "Total R: 120.0\n",
      "Total R: 210.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  1260\n",
      "Total R: 240.0\n",
      "Total R: 310.0\n",
      "Total R: 490.0\n",
      "Total R: 325.0\n",
      "Total R: 410.0\n",
      "Total R: 30.0\n",
      "Total R: 80.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1270\n",
      "Total R: 50.0\n",
      "Total R: 55.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1280\n",
      "Total R: 135.0\n",
      "Total R: 180.0\n",
      "Total R: 90.0\n",
      "Total R: 210.0\n",
      "Total R: 110.0\n",
      "Total R: 255.0\n",
      "Total R: 425.0\n",
      "Elapsed time(s):  1290\n",
      "Total R: 105.0\n",
      "Total R: 120.0\n",
      "Total R: 180.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Total R: 135.0\n",
      "Total R: 50.0\n",
      "Total R: 140.0\n",
      "Elapsed time(s):  1300\n",
      "Total R: 215.0\n",
      "Total R: 65.0\n",
      "Total R: 30.0\n",
      "Total R: 210.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1310\n",
      "Total R: 155.0\n",
      "Total R: 445.0\n",
      "Total R: 30.0\n",
      "Total R: 120.0\n",
      "Total R: 60.0\n",
      "Total R: 180.0\n",
      "Total R: 310.0\n",
      "Total R: 75.0\n",
      "Total R: 215.0\n",
      "Elapsed time(s):  1320\n",
      "Total R: 305.0\n",
      "Total R: 235.0\n",
      "Total R: 75.0\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Total R: 80.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1330\n",
      "Total R: 110.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1340\n",
      "Total R: 120.0\n",
      "Total R: 260.0\n",
      "Total R: 230.0\n",
      "Total R: 255.0\n",
      "Total R: 430.0\n",
      "Elapsed time(s):  1350\n",
      "Total R: 105.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total R: 55.0\n",
      "Total R: 130.0\n",
      "Total R: 110.0\n",
      "Total R: 60.0\n",
      "Total R: 75.0\n",
      "Total R: 80.0\n",
      "Total R: 125.0\n",
      "Elapsed time(s):  1360\n",
      "Total R: 55.0\n",
      "Total R: 5.0\n",
      "Total R: 155.0\n",
      "Total R: 80.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  1370\n",
      "Total R: 120.0\n",
      "Total R: 305.0\n",
      "Total R: 120.0\n",
      "Total R: 90.0\n",
      "Total R: 155.0\n",
      "Total R: 35.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Total R: 5.0\n",
      "Total R: 80.0\n",
      "Elapsed time(s):  1380\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Total R: 45.0\n",
      "Total R: 80.0\n",
      "Total R: 410.0\n",
      "Elapsed time(s):  1390\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 275.0\n",
      "Total R: 65.0\n",
      "Total R: 210.0\n",
      "Total R: 15.0\n",
      "Total R: 80.0\n",
      "Elapsed time(s):  1400\n",
      "Total R: 30.0\n",
      "Total R: 210.0\n",
      "Total R: 30.0\n",
      "Total R: 110.0\n",
      "Total R: 100.0\n",
      "Total R: 20.0\n",
      "Elapsed time(s):  1410\n",
      "Total R: 30.0\n",
      "Total R: 110.0\n",
      "Total R: 170.0\n",
      "Total R: 80.0\n",
      "Total R: 260.0\n",
      "Total R: 55.0\n",
      "Total R: 140.0\n",
      "Elapsed time(s):  1420\n",
      "Total R: 260.0\n",
      "Total R: 100.0\n",
      "Total R: 20.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1430\n",
      "Total R: 75.0\n",
      "Total R: 110.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Total R: 210.0\n",
      "Total R: 180.0\n",
      "Total R: 165.0\n",
      "Elapsed time(s):  1440\n",
      "Total R: 80.0\n",
      "Total R: 140.0\n",
      "Total R: 80.0\n",
      "Total R: 240.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  1450\n",
      "Total R: 15.0\n",
      "Total R: 135.0\n",
      "Total R: 140.0\n",
      "Total R: 110.0\n",
      "Total R: 40.0\n",
      "Total R: 110.0\n",
      "Total R: 165.0\n",
      "Elapsed time(s):  1460\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 110.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 55.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1470\n",
      "Total R: 50.0\n",
      "Total R: 55.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 135.0\n",
      "Total R: 80.0\n",
      "Total R: 155.0\n",
      "Total R: 120.0\n",
      "Total R: 120.0\n",
      "Elapsed time(s):  1480\n",
      "Total R: 280.0\n",
      "Total R: 75.0\n",
      "Total R: 50.0\n",
      "Total R: 30.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  1490\n",
      "Total R: 120.0\n",
      "Total R: 30.0\n",
      "Total R: 35.0\n",
      "Total R: 165.0\n",
      "Elapsed time(s):  1500\n",
      "Total R: 120.0\n",
      "Total R: 20.0\n",
      "Total R: 165.0\n",
      "Total R: 150.0\n",
      "Total R: 15.0\n",
      "Total R: 160.0\n",
      "Total R: 15.0\n",
      "Elapsed time(s):  1510\n",
      "Total R: 80.0\n",
      "Total R: 50.0\n",
      "Total R: 155.0\n",
      "Total R: 50.0\n",
      "Total R: 110.0\n",
      "Total R: 120.0\n",
      "Total R: 30.0\n",
      "Total R: 50.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  1520\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 50.0\n",
      "Total R: 30.0\n",
      "Total R: 210.0\n",
      "Total R: 135.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1530\n",
      "Total R: 135.0\n",
      "Total R: 75.0\n",
      "Total R: 110.0\n",
      "Total R: 135.0\n",
      "Total R: 5.0\n",
      "Total R: 65.0\n",
      "Elapsed time(s):  1540\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 30.0\n",
      "Total R: 65.0\n",
      "Total R: 240.0\n",
      "Elapsed time(s):  1550\n",
      "Total R: 20.0\n",
      "Total R: 55.0\n",
      "Total R: 5.0\n",
      "Total R: 140.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 80.0\n",
      "Total R: 140.0\n",
      "Elapsed time(s):  1560\n",
      "Total R: 75.0\n",
      "Total R: 80.0\n",
      "Total R: 105.0\n",
      "Total R: 60.0\n",
      "Total R: 145.0\n",
      "Total R: 240.0\n",
      "Elapsed time(s):  1570\n",
      "Total R: 180.0\n",
      "Total R: 135.0\n",
      "Total R: 60.0\n",
      "Total R: 80.0\n",
      "Total R: 155.0\n",
      "Total R: 5.0\n",
      "Total R: 50.0\n",
      "Total R: 120.0\n",
      "Total R: 55.0\n",
      "Total R: 45.0\n",
      "Elapsed time(s):  1580\n",
      "Total R: 35.0\n",
      "Total R: 0.0\n",
      "Total R: 65.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1590\n",
      "Total R: 45.0\n",
      "Total R: 120.0\n",
      "Total R: 50.0\n",
      "Total R: 110.0\n",
      "Total R: 320.0\n",
      "Total R: 105.0\n",
      "Total R: 5.0\n",
      "Elapsed time(s):  1600\n",
      "Total R: 30.0\n",
      "Total R: 80.0\n",
      "Total R: 100.0\n",
      "Total R: 110.0\n",
      "Total R: 135.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Total R: 35.0\n",
      "Total R: 50.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1610\n",
      "Total R: 105.0\n",
      "Total R: 15.0\n",
      "Total R: 30.0\n",
      "Total R: 30.0\n",
      "Total R: 70.0\n",
      "Total R: 70.0\n",
      "Elapsed time(s):  1620\n",
      "Total R: 95.0\n",
      "Total R: 80.0\n",
      "Total R: 160.0\n",
      "Total R: 85.0\n",
      "Total R: 45.0\n",
      "Total R: 35.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1630\n",
      "Total R: 105.0\n",
      "Total R: 210.0\n",
      "Total R: 105.0\n",
      "Total R: 105.0\n",
      "Total R: 75.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1640\n",
      "Total R: 75.0\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Total R: 135.0\n",
      "Total R: 180.0\n",
      "Total R: 40.0\n",
      "Total R: 180.0\n",
      "Total R: 250.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1650\n",
      "Total R: 105.0\n",
      "Total R: 5.0\n",
      "Total R: 105.0\n",
      "Total R: 15.0\n",
      "Total R: 50.0\n",
      "Total R: 5.0\n",
      "Elapsed time(s):  1660\n",
      "Total R: 10.0\n",
      "Total R: 90.0\n",
      "Total R: 105.0\n",
      "Total R: 15.0\n",
      "Total R: 105.0\n",
      "Total R: 185.0\n",
      "Total R: 135.0\n",
      "Total R: 155.0\n",
      "Total R: 105.0\n",
      "Total R: 65.0\n",
      "Total R: 105.0\n",
      "Total R: 30.0\n",
      "Total R: 70.0\n",
      "Total R: 390.0\n",
      "Elapsed time(s):  1670\n",
      "Total R: 15.0\n",
      "Total R: 135.0\n",
      "Total R: 65.0\n",
      "Total R: 120.0\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1680\n",
      "Total R: 180.0\n",
      "Total R: 105.0\n",
      "Total R: 50.0\n",
      "Total R: 80.0\n",
      "Total R: 15.0\n",
      "Total R: 485.0\n",
      "Total R: 30.0\n",
      "Total R: 125.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1690\n",
      "Total R: 50.0\n",
      "Total R: 145.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Total R: 75.0\n",
      "Elapsed time(s):  1700\n",
      "Total R: 125.0\n",
      "Total R: 85.0\n",
      "Total R: 75.0\n",
      "Total R: 15.0\n",
      "Total R: 60.0\n",
      "Total R: 30.0\n",
      "Total R: 15.0\n",
      "Total R: 105.0\n",
      "Elapsed time(s):  1710\n",
      "Total R: 5.0\n",
      "Total R: 20.0\n",
      "Total R: 110.0\n",
      "Total R: 15.0\n",
      "Total R: 135.0\n",
      "Total R: 85.0\n",
      "Total R: 245.0\n",
      "Elapsed time(s):  1720\n",
      "Total R: 155.0\n",
      "Total R: 210.0\n",
      "Total R: 5.0\n",
      "Total R: 100.0\n",
      "Total R: 40.0\n",
      "Total R: 30.0\n",
      "Elapsed time(s):  1730\n",
      "Total R: 20.0\n",
      "Total R: 380.0\n",
      "Total R: 50.0\n",
      "Total R: 30.0\n",
      "Total R: 30.0\n",
      "Total R: 135.0\n",
      "Elapsed time(s):  1740\n",
      "Total R: 105.0\n",
      "Total R: 5.0\n",
      "Total R: 35.0\n",
      "Total R: 250.0\n",
      "Total R: 280.0\n",
      "Total R: 30.0\n",
      "Total R: 50.0\n",
      "Elapsed time(s):  1750\n",
      "Total R: 100.0\n",
      "Total R: 30.0\n",
      "Total R: 75.0\n",
      "Total R: 105.0\n",
      "Total R: 135.0\n",
      "Total R: 50.0\n",
      "Total R: 105.0\n",
      "Total R: 60.0\n",
      "Elapsed time(s):  1760\n",
      "Total R: 30.0\n",
      "Total R: 35.0\n",
      "Total R: 5.0\n",
      "Total R: 75.0\n",
      "Total R: 35.0\n",
      "Total R: 5.0\n",
      "Total R: 75.0\n",
      "Total R: 35.0\n",
      "Total R: 15.0\n",
      "Elapsed time(s):  1770\n",
      "Total R: 15.0\n",
      "Total R: 155.0\n",
      "Total R: 30.0\n",
      "Total R: 135.0\n",
      "Total R: 40.0\n",
      "Elapsed time(s):  1780\n",
      "Total R: 135.0\n",
      "Total R: 55.0\n",
      "Total R: 35.0\n",
      "Total R: 25.0\n",
      "Total R: 45.0\n",
      "Total R: 110.0\n",
      "Elapsed time(s):  1790\n",
      "Total R: 45.0\n",
      "Total R: 30.0\n",
      "Total R:Total R: 20.0\n",
      " 0.0\n",
      "Total R: 50.0\n",
      "Total R:Total R: 105.0\n",
      "Total R: 5.0\n",
      " 30.0\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# OpenGym CartPole-v0 with A3C on GPU\n",
    "# -----------------------------------\n",
    "#\n",
    "# A3C implementation with GPU optimizer threads.\n",
    "# \n",
    "# Made as part of blog series Let's make an A3C, available at\n",
    "# https://jaromiru.com/2017/02/16/lets-make-an-a3c-theory/\n",
    "#\n",
    "# author: Jaromir Janisch, 2017\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gym, time, random, threading\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "\n",
    "#-- constants\n",
    "ENV = 'SpaceInvaders-ram-v4'\n",
    "\n",
    "Reward = []\n",
    "Reward_index = []\n",
    "timer = 0\n",
    "HOUR = 3600\n",
    "RUN_TIME = HOUR*0.5\n",
    "THREADS = 8\n",
    "OPTIMIZERS = 2\n",
    "THREAD_DELAY = 0.001\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "N_STEP_RETURN = 8\n",
    "GAMMA_N = GAMMA ** N_STEP_RETURN\n",
    "\n",
    "EPS_START = 0.9\n",
    "EPS_STOP  = .15\n",
    "EPS_STEPS = RUN_TIME*0.95\n",
    "\n",
    "MIN_BATCH = 32\n",
    "LEARNING_RATE = 5e-3\n",
    "LOSS_V = .5\t\t\t# v loss coefficient\n",
    "LOSS_ENTROPY = .01 \t# entropy coefficient\n",
    "\n",
    "#---------\n",
    "class Brain:\n",
    "    train_queue = [ [], [], [], [], [] ]\t# s, a, r, s', s' terminal mask\n",
    "    lock_queue = threading.Lock()\n",
    "\n",
    "    def __init__(self):\n",
    "        self.session = tf.Session()\n",
    "        K.set_session(self.session)\n",
    "        K.manual_variable_initialization(True)\n",
    "\n",
    "        self.model = self._build_model()\n",
    "        self.graph = self._build_graph(self.model)\n",
    "\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        self.default_graph = tf.get_default_graph()\n",
    "\n",
    "        self.default_graph.finalize()\t# avoid modifications\n",
    "\n",
    "    def _build_model(self):\n",
    "\n",
    "        l_input = Input( batch_shape=(None, NUM_STATE) )\n",
    "        l_dense = Dense(16, activation='relu')(l_input)\n",
    "\n",
    "        out_actions = Dense(NUM_ACTIONS, activation='softmax')(l_dense)\n",
    "        out_value   = Dense(1, activation='linear')(l_dense)\n",
    "\n",
    "        model = Model(inputs=[l_input], outputs=[out_actions, out_value])\n",
    "        model._make_predict_function()\t# have to initialize before threading\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _build_graph(self, model):\n",
    "        s_t = tf.placeholder(tf.float32, shape=(None, NUM_STATE))\n",
    "        a_t = tf.placeholder(tf.float32, shape=(None, NUM_ACTIONS))\n",
    "        r_t = tf.placeholder(tf.float32, shape=(None, 1)) # not immediate, but discounted n step reward\n",
    "        \n",
    "        p, v = model(s_t)\n",
    "\n",
    "        log_prob = tf.log( tf.reduce_sum(p * a_t, axis=1, keep_dims=True) + 1e-10)\n",
    "        advantage = r_t - v\n",
    "\n",
    "        loss_policy = - log_prob * tf.stop_gradient(advantage)\t\t\t\t\t\t\t\t\t# maximize policy\n",
    "        loss_value  = LOSS_V * tf.square(advantage)\t\t\t\t\t\t\t\t\t\t\t\t# minimize value error\n",
    "        entropy = LOSS_ENTROPY * tf.reduce_sum(p * tf.log(p + 1e-10), axis=1, keep_dims=True)\t# maximize entropy (regularization)\n",
    "\n",
    "        loss_total = tf.reduce_mean(loss_policy + loss_value + entropy)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(LEARNING_RATE, decay=.99)\n",
    "        minimize = optimizer.minimize(loss_total)\n",
    "\n",
    "        return s_t, a_t, r_t, minimize\n",
    "\n",
    "    def optimize(self):\n",
    "        if len(self.train_queue[0]) < MIN_BATCH:\n",
    "            time.sleep(0)\t# yield\n",
    "            return\n",
    "\n",
    "        with self.lock_queue:\n",
    "            if len(self.train_queue[0]) < MIN_BATCH:\t# more thread could have passed without lock\n",
    "                return \t\t\t\t\t\t\t\t\t# we can't yield inside lock\n",
    "\n",
    "            s, a, r, s_, s_mask = self.train_queue\n",
    "            self.train_queue = [ [], [], [], [], [] ]\n",
    "\n",
    "        s = np.vstack(s)\n",
    "        a = np.vstack(a)\n",
    "        r = np.vstack(r)\n",
    "        s_ = np.vstack(s_)\n",
    "        s_mask = np.vstack(s_mask)\n",
    "\n",
    "        if len(s) > 5*MIN_BATCH: print(\"Optimizer alert! Minimizing batch of %d\" % len(s))\n",
    "\n",
    "        v = self.predict_v(s_)\n",
    "        r = r + GAMMA_N * v * s_mask\t# set v to 0 where s_ is terminal state\n",
    "        \n",
    "        s_t, a_t, r_t, minimize = self.graph\n",
    "        self.session.run(minimize, feed_dict={s_t: s, a_t: a, r_t: r})\n",
    "\n",
    "    def train_push(self, s, a, r, s_):\n",
    "        with self.lock_queue:\n",
    "            self.train_queue[0].append(s)\n",
    "            self.train_queue[1].append(a)\n",
    "            self.train_queue[2].append(r)\n",
    "\n",
    "            if s_ is None:\n",
    "                self.train_queue[3].append(NONE_STATE)\n",
    "                self.train_queue[4].append(0.)\n",
    "            else:\t\n",
    "                self.train_queue[3].append(s_)\n",
    "                self.train_queue[4].append(1.)\n",
    "\n",
    "    def predict(self, s):\n",
    "        with self.default_graph.as_default():\n",
    "            p, v = self.model.predict(s)\n",
    "            return p, v\n",
    "\n",
    "    def predict_p(self, s):\n",
    "        with self.default_graph.as_default():\n",
    "            p, v = self.model.predict(s)\t\t\n",
    "            return p\n",
    "\n",
    "    def predict_v(self, s):\n",
    "        with self.default_graph.as_default():\n",
    "            p, v = self.model.predict(s)\t\t\n",
    "            return v\n",
    "\n",
    "#---------\n",
    "frames = 0\n",
    "class Agent:\n",
    "    def __init__(self, eps_start, eps_end, eps_steps):\n",
    "        self.eps_start = eps_start\n",
    "        self.eps_end   = eps_end\n",
    "        self.eps_steps = eps_steps\n",
    "\n",
    "        self.memory = []\t# used for n_step return\n",
    "        self.R = 0.\n",
    "\n",
    "    def getEpsilon(self):\n",
    "        if(timer >= self.eps_steps):\n",
    "            return self.eps_end\n",
    "        else:\n",
    "            return self.eps_start + timer * (self.eps_end - self.eps_start) / self.eps_steps\t# linearly interpolate\n",
    "\n",
    "    def act(self, s):\n",
    "        eps = self.getEpsilon()\t\t\t\n",
    "        global frames; frames = frames + 1\n",
    "\n",
    "        if random.random() < eps:\n",
    "            return random.randint(0, NUM_ACTIONS-1)\n",
    "\n",
    "        else:\n",
    "            s = np.array([s])\n",
    "            p = brain.predict_p(s)[0]\n",
    "\n",
    "            # a = np.argmax(p)\n",
    "            a = np.random.choice(NUM_ACTIONS, p=p)\n",
    "\n",
    "            return a\n",
    "    \n",
    "    def train(self, s, a, r, s_):\n",
    "        def get_sample(memory, n):\n",
    "            s, a, _, _  = memory[0]\n",
    "            _, _, _, s_ = memory[n-1]\n",
    "\n",
    "            return s, a, self.R, s_\n",
    "\n",
    "        a_cats = np.zeros(NUM_ACTIONS)\t# turn action into one-hot representation\n",
    "        a_cats[a] = 1 \n",
    "\n",
    "        self.memory.append( (s, a_cats, r, s_) )\n",
    "\n",
    "        self.R = ( self.R + r * GAMMA_N ) / GAMMA\n",
    "\n",
    "        if s_ is None:\n",
    "            while len(self.memory) > 0:\n",
    "                n = len(self.memory)\n",
    "                s, a, r, s_ = get_sample(self.memory, n)\n",
    "                brain.train_push(s, a, r, s_)\n",
    "\n",
    "                self.R = ( self.R - self.memory[0][2] ) / GAMMA\n",
    "                self.memory.pop(0)\t\t\n",
    "\n",
    "            self.R = 0\n",
    "\n",
    "        if len(self.memory) >= N_STEP_RETURN:\n",
    "            s, a, r, s_ = get_sample(self.memory, N_STEP_RETURN)\n",
    "            brain.train_push(s, a, r, s_)\n",
    "\n",
    "            self.R = self.R - self.memory[0][2]\n",
    "            self.memory.pop(0)\t\n",
    "\n",
    "    # possible edge case - if an episode ends in <N steps, the computation is incorrect\n",
    "\n",
    "#---------\n",
    "class Environment(threading.Thread):\n",
    "    stop_signal = False\n",
    "\n",
    "    def __init__(self, render=False, eps_start=EPS_START, eps_end=EPS_STOP, eps_steps=EPS_STEPS):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "        self.render = render\n",
    "        self.env = gym.make(ENV)\n",
    "        self.agent = Agent(eps_start, eps_end, eps_steps)\n",
    "\n",
    "    def runEpisode(self):\n",
    "        s = self.env.reset()\n",
    "\n",
    "        R = 0\n",
    "        while True:         \n",
    "            time.sleep(THREAD_DELAY) # yield \n",
    "\n",
    "            if self.render: self.env.render()\n",
    "\n",
    "            a = self.agent.act(s)\n",
    "            s_, r, done, info = self.env.step(a)\n",
    "\n",
    "            if done: # terminal state\n",
    "                s_ = None\n",
    "\n",
    "            self.agent.train(s, a, r, s_)\n",
    "\n",
    "            s = s_\n",
    "            R += r\n",
    "            if done or self.stop_signal:\n",
    "                break\n",
    "        Reward.append(R)\n",
    "        print(\"Total R:\", R)\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop_signal:\n",
    "            self.runEpisode()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_signal = True\n",
    "\n",
    "#---------\n",
    "class Optimizer(threading.Thread):\n",
    "    stop_signal = False\n",
    "\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop_signal:\n",
    "            brain.optimize()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_signal = True\n",
    "\n",
    "#-- main\n",
    "env_test = Environment(render=True, eps_start=0., eps_end=0.)\n",
    "NUM_STATE = env_test.env.observation_space.shape[0]\n",
    "NUM_ACTIONS = env_test.env.action_space.n\n",
    "NONE_STATE = np.zeros(NUM_STATE)\n",
    "\n",
    "brain = Brain()\t# brain is global in A3C\n",
    "\n",
    "envs = [Environment() for i in range(THREADS)]\n",
    "opts = [Optimizer() for i in range(OPTIMIZERS)]\n",
    "\n",
    "for o in opts:\n",
    "    o.start()\n",
    "\n",
    "for e in envs:\n",
    "    e.start()\n",
    "\n",
    "for i in range(0, int(RUN_TIME/10)):\n",
    "    time.sleep(10)\n",
    "    if not Reward:\n",
    "        if not Reward_index:\n",
    "            Reward_index.append(0)\n",
    "        else:\n",
    "            Reward_index.append(Reward_index[-1])\n",
    "    else:\n",
    "        avg_rew = 0\n",
    "        avg_rew = sum(Reward)/len(Reward)\n",
    "        Reward_index.append(avg_rew)\n",
    "    Reward=[]\n",
    "    timer += 10    \n",
    "    print(\"Elapsed time(s): \", i*10)\n",
    "\n",
    "for e in envs:\n",
    "    e.stop()\n",
    "for e in envs:\n",
    "    e.join()\n",
    "\n",
    "for o in opts:\n",
    "    o.stop()\n",
    "for o in opts:\n",
    "    o.join()\n",
    "\n",
    "#serializers.save_hdf5('test_save', brain.model)\n",
    "#serializers.save_hdf5('test_save' + '.opt', opts)\n",
    "#brain.model.save('test_save_mod.h5')\n",
    "#opts.save('test_save_opt.h5')\n",
    "print(\"Training finished\")\n",
    "#env_test.run()\n",
    "                                               \n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total R: 0.0\n",
      "Total R: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-368a37544554>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(Reward_index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menv_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#env_test.close();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ee80affde6fb>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_signal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunEpisode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ee80affde6fb>\u001b[0m in \u001b[0;36mrunEpisode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTHREAD_DELAY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print(Reward_index)\n",
    "env_test.run()\n",
    "#env_test.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import gym\n",
    "\n",
    "import copy\n",
    "\n",
    "from logging import getLogger\n",
    "from gym import error, spaces\n",
    "from gym import utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "import chainer\n",
    "\n",
    "from chainer import serializers\n",
    "\n",
    "from chainer import functions as F\n",
    "\n",
    "\n",
    "try:\n",
    "    import atari_py\n",
    "except ImportError as e:\n",
    "    raise error.DependencyNotInstalled(\"{}. (HINT: you can install Atari dependencies by running 'pip install gym[atari]'.)\".format(e))\n",
    "    \n",
    "def to_ram(ale):\n",
    "    ram_size = ale.getRAMSize()\n",
    "    ram = np.zeros((ram_size),dtype=np.uint8)\n",
    "    ale.getRAM(ram)\n",
    "    return ram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_episodes = 1\n",
    "env = gym.make(\"SpaceInvaders-ram-v0\")\n",
    "\n",
    "for i in range(num_episodes):\n",
    "        state = env.reset() #reset to initial state\n",
    "        state = np.expand_dims(state, axis=0)/2\n",
    "        terminal = False # reset terminal flag\n",
    "        while not terminal:\n",
    "            env.render()\n",
    "            time.sleep(.05)\n",
    "            q_values = model.get_q_values(state)\n",
    "            policy = eps_greedy_policy(q_values.squeeze(), .1) # greedy policy\n",
    "            action = np.random.choice(num_actions, p=policy)\n",
    "            state, reward, terminal, _ = env.step(action) # take one step in the evironment\n",
    "            state = np.expand_dims(state, axis=0)/2\n",
    "# close window\n",
    "env.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from keras.utils.np_utils import to_categorical as one_hot\n",
    "from collections import namedtuple\n",
    "from dqn_model import DoubleQLearningModel, ExperienceReplay\n",
    "\n",
    "def train_loop_ddqn(model, env, num_episodes, batch_size=64, gamma=.94):        \n",
    "    Transition = namedtuple(\"Transition\", [\"s\", \"a\", \"r\", \"next_s\", \"t\"])\n",
    "    eps = 1.\n",
    "    eps_end = .1 \n",
    "    eps_decay = .0005\n",
    "    R_buffer = []\n",
    "    R_avg = []\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset() #reset to initial state\n",
    "        state = np.expand_dims(state, axis=0)/2\n",
    "        terminal = False # reset terminal flag\n",
    "        ep_reward = 0\n",
    "        q_buffer = []\n",
    "        steps = 0\n",
    "        while not terminal:\n",
    "            env.render() # comment this line out if jous' don't want to render the environment\n",
    "            steps += 1\n",
    "            q_values = model.get_q_values(state)\n",
    "            q_buffer.append(q_values)\n",
    "            policy = eps_greedy_policy(q_values.squeeze(), eps) \n",
    "            action = np.random.choice(num_actions, p=policy) # sample action from epsilon-greedy policy\n",
    "            new_state, reward, terminal, _ = env.step(action) # take one step in the evironment\n",
    "            new_state = np.expand_dims(new_state, axis=0)/2\n",
    "            \n",
    "            # only use the terminal flag for ending the episode and not for training\n",
    "            # if the flag is set due to that the maximum amount of steps is reached \n",
    "            t_to_buffer = terminal if not steps == 200 else False\n",
    "            \n",
    "            # store data to replay buffer\n",
    "            replay_buffer.add(Transition(s=state, a=action, r=reward, next_s=new_state, t=t_to_buffer))\n",
    "            state = new_state\n",
    "            ep_reward += reward\n",
    "            \n",
    "            # if buffer contains more than 1000 samples, perform one training step\n",
    "            if replay_buffer.buffer_length > 1000:\n",
    "                s, a, r, s_, t = replay_buffer.sample_minibatch(batch_size) # sample a minibatch of transitions\n",
    "                q_1, q_2 = model.get_q_values_for_both_models(np.squeeze(s_))\n",
    "                td_target = calculate_td_targets(q_1, q_2, r, t, gamma)\n",
    "                model.update(s, td_target, a)    \n",
    "                \n",
    "        eps = max(eps - eps_decay, eps_end) # decrease epsilon        \n",
    "        R_buffer.append(ep_reward)\n",
    "        \n",
    "        # running average of episodic rewards\n",
    "        R_avg.append(.05 * R_buffer[i] + .95 * R_avg[i-1]) if i > 0 else R_avg.append(R_buffer[i])\n",
    "        print('Episode: ', i, 'Reward:', ep_reward, 'Epsilon', eps, 'mean q', np.mean(np.array(q_buffer)))\n",
    "        \n",
    "        # if running average > 195, the task is considerd solved\n",
    "    return R_buffer, R_avg\n",
    "\n",
    "class AtariEnv(gym.Env, utils.EzPickle):\n",
    "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "\n",
    "    def __init__(self, game='SpaceInvaders-v0', obs_type='ram', frameskip=(2, 5), repeat_action_probability=0.):\n",
    "        \"\"\"Frameskip should be either a tuple (indicating a random range to\n",
    "        choose from, with the top value exclude), or an int.\"\"\"\n",
    "\n",
    "        utils.EzPickle.__init__(self, game, obs_type, frameskip, repeat_action_probability)\n",
    "        assert obs_type in ('ram', 'image')\n",
    "\n",
    "        self.game_path = atari_py.get_game_path(game)\n",
    "        if not os.path.exists(self.game_path):\n",
    "            raise IOError('You asked for game %s but path %s does not exist'%(game, self.game_path))\n",
    "        self._obs_type = obs_type\n",
    "        self.frameskip = frameskip\n",
    "        self.ale = atari_py.ALEInterface()\n",
    "        self.viewer = None\n",
    "\n",
    "        # Tune (or disable) ALE's action repeat:\n",
    "        # https://github.com/openai/gym/issues/349\n",
    "        assert isinstance(repeat_action_probability, (float, int)), \"Invalid repeat_action_probability: {!r}\".format(repeat_action_probability)\n",
    "        self.ale.setFloat('repeat_action_probability'.encode('utf-8'), repeat_action_probability)\n",
    "\n",
    "        self.seed()\n",
    "\n",
    "        self._action_set = self.ale.getMinimalActionSet()\n",
    "        self.action_space = spaces.Discrete(len(self._action_set))\n",
    "\n",
    "        (screen_width,screen_height) = self.ale.getScreenDims()\n",
    "        if self._obs_type == 'ram':\n",
    "            self.observation_space = spaces.Box(low=0, high=255, dtype=np.uint8, shape=(128,))\n",
    "        elif self._obs_type == 'image':\n",
    "            self.observation_space = spaces.Box(low=0, high=255, shape=(screen_height, screen_width, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            raise error.Error('Unrecognized observation type: {}'.format(self._obs_type))\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed1 = seeding.np_random(seed)\n",
    "        # Derive a random seed. This gets passed as a uint, but gets\n",
    "        # checked as an int elsewhere, so we need to keep it below\n",
    "        # 2**31.\n",
    "        seed2 = seeding.hash_seed(seed1 + 1) % 2**31\n",
    "        # Empirically, we need to seed before loading the ROM.\n",
    "        self.ale.setInt(b'random_seed', seed2)\n",
    "        self.ale.loadROM(self.game_path)\n",
    "        return [seed1, seed2]\n",
    "\n",
    "    def step(self, a):\n",
    "        reward = 0.0\n",
    "        action = self._action_set[a]\n",
    "\n",
    "        if isinstance(self.frameskip, int):\n",
    "            num_steps = self.frameskip\n",
    "        else:\n",
    "            num_steps = self.np_random.randint(self.frameskip[0], self.frameskip[1])\n",
    "        for _ in range(num_steps):\n",
    "            reward += self.ale.act(action)\n",
    "        ob = self._get_obs()\n",
    "\n",
    "        return ob, reward, self.ale.game_over(), {\"ale.lives\": self.ale.lives()}\n",
    "\n",
    "    def _get_image(self):\n",
    "        return self.ale.getScreenRGB2()\n",
    "\n",
    "    def _get_ram(self):\n",
    "        return to_ram(self.ale)\n",
    "\n",
    "    @property\n",
    "    def _n_actions(self):\n",
    "        return len(self._action_set)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        if self._obs_type == 'ram':\n",
    "            return self._get_ram()\n",
    "        elif self._obs_type == 'image':\n",
    "            img = self._get_image()\n",
    "        return img\n",
    "\n",
    "    # return: (states, observations)\n",
    "    def reset(self):\n",
    "        self.ale.reset_game()\n",
    "        return self._get_obs()\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        img = self._get_image()\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "    def get_action_meanings(self):\n",
    "        return [ACTION_MEANING[i] for i in self._action_set]\n",
    "\n",
    "    def get_keys_to_action(self):\n",
    "        KEYWORD_TO_KEY = {\n",
    "            'UP':      ord('w'),\n",
    "            'DOWN':    ord('s'),\n",
    "            'LEFT':    ord('a'),\n",
    "            'RIGHT':   ord('d'),\n",
    "            'FIRE':    ord(' '),\n",
    "        }\n",
    "\n",
    "        keys_to_action = {}\n",
    "\n",
    "        for action_id, action_meaning in enumerate(self.get_action_meanings()):\n",
    "            keys = []\n",
    "            for keyword, key in KEYWORD_TO_KEY.items():\n",
    "                if keyword in action_meaning:\n",
    "                    keys.append(key)\n",
    "            keys = tuple(sorted(keys))\n",
    "\n",
    "            assert keys not in keys_to_action\n",
    "            keys_to_action[keys] = action_id\n",
    "\n",
    "        return keys_to_action\n",
    "\n",
    "    def clone_state(self):\n",
    "        \"\"\"Clone emulator state w/o system state. Restoring this state will\n",
    "        *not* give an identical environment. For complete cloning and restoring\n",
    "        of the full state, see `{clone,restore}_full_state()`.\"\"\"\n",
    "        state_ref = self.ale.cloneState()\n",
    "        state = self.ale.encodeState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "        return state\n",
    "\n",
    "    def restore_state(self, state):\n",
    "        \"\"\"Restore emulator state w/o system state.\"\"\"\n",
    "        state_ref = self.ale.decodeState(state)\n",
    "        self.ale.restoreState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "\n",
    "    def clone_full_state(self):\n",
    "        \"\"\"Clone emulator state w/ system state including pseudorandomness.\n",
    "        Restoring this state will give an identical environment.\"\"\"\n",
    "        state_ref = self.ale.cloneSystemState()\n",
    "        state = self.ale.encodeState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "        return state\n",
    "\n",
    "    def restore_full_state(self, state):\n",
    "        \"\"\"Restore emulator state w/ system state including pseudorandomness.\"\"\"\n",
    "        state_ref = self.ale.decodeState(state)\n",
    "        self.ale.restoreSystemState(state_ref)\n",
    "        self.ale.deleteState(state_ref)\n",
    "\n",
    "ACTION_MEANING = {\n",
    "    0 : \"NOOP\",\n",
    "    1 : \"FIRE\",\n",
    "    2 : \"UP\",\n",
    "    3 : \"RIGHT\",\n",
    "    4 : \"LEFT\",\n",
    "    5 : \"DOWN\",\n",
    "    6 : \"UPRIGHT\",\n",
    "    7 : \"UPLEFT\",\n",
    "    8 : \"DOWNRIGHT\",\n",
    "    9 : \"DOWNLEFT\",\n",
    "    10 : \"UPFIRE\",\n",
    "    11 : \"RIGHTFIRE\",\n",
    "    12 : \"LEFTFIRE\",\n",
    "    13 : \"DOWNFIRE\",\n",
    "    14 : \"UPRIGHTFIRE\",\n",
    "    15 : \"UPLEFTFIRE\",\n",
    "    16 : \"DOWNRIGHTFIRE\",\n",
    "    17 : \"DOWNLEFTFIRE\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
